{
  "name": "gpt-oss-120b-max",
  "version": "1.0.0",
  "description": "Ollama server mimic that exposes gpt-oss-120b and gpt-oss-20b through Ollama Turbo subscription for blazing fast AI in tools like JetBrains",
  "type": "module",
  "scripts": {
    "dev": "bun --watch run index.ts",
    "dev:debug": "bun --watch --inspect run index.ts",
    "dev:hot": "bun --hot run index.ts",
    "start": "bun run index.ts",
    "start:prod": "NODE_ENV=production bun run index.ts",
    "start-with-qdrant": "concurrently -n \"server,qdrant\" -c \"cyan.bold,magenta.bold\" --prefix \"[{name}]\" \"bun run index.ts\" \"bun run start-qdrant\"",
    "start-qdrant": "docker run -p 6333:6333 -p 6334:6334 -v \"$(pwd)/qdrant_storage:/qdrant/storage:z\" qdrant/qdrant > /dev/null 2>&1",
    "test": "bun test",
    "typecheck": "tsc --noEmit",
    "clean": "rm -rf logs/*.log"
  },
  "dependencies": {
    "ollama": "^0.5.0"
  },
  "devDependencies": {
    "@types/bun": "latest",
    "concurrently": "^9.2.0",
    "typescript": "^5.0.0"
  }
}
